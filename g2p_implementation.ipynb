{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2kF/kc5+pG2HpAq3/lyPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhilitcode/DaveAI_Internship/blob/main/g2p_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmXyEinVkDIp",
        "outputId": "426c2372-7d15-4703-98f1-107e759de92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting g2p_en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (1.26.4)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (3.8.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (7.4.0)\n",
            "Collecting distance>=0.1.3 (from g2p_en)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p_en) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p_en) (4.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en) (4.12.2)\n",
            "Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16257 sha256=77ec13c1d2c4c78dafa9e5977158805bc492858d6252fc1a144ed7776ccaa7da\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "Successfully built distance\n",
            "Installing collected packages: distance, g2p_en\n",
            "Successfully installed distance-0.1.3 g2p_en-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install g2p_en"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from g2p_en import G2p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfev88l8kNLi",
        "outputId": "6cd6cfea-5bff-44e3-cdc1-81bd228fd28b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"I have $250 in my pocket.\", # number -> spell-out\n",
        "         \"popular pets, e.g. cats and dogs\", # e.g. -> for example\n",
        "         \"I refuse to collect the refuse around here.\", # homograph\n",
        "         \"I'm an activationist.\"] # newly coined word]"
      ],
      "metadata": {
        "id": "UDM-kXPBknqD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g2p = G2p()"
      ],
      "metadata": {
        "id": "erJs3R5KmHpN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in texts:\n",
        "  out = g2p(text)\n",
        "  print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sfu4mZDl75H",
        "outputId": "0fc28446-a110-4f97-bf1d-cddf3d49bbf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AY1', ' ', 'HH', 'AE1', 'V', ' ', 'T', 'UW1', ' ', 'HH', 'AH1', 'N', 'D', 'R', 'AH0', 'D', ' ', 'F', 'IH1', 'F', 'T', 'IY0', ' ', 'D', 'AA1', 'L', 'ER0', 'Z', ' ', 'IH0', 'N', ' ', 'M', 'AY1', ' ', 'P', 'AA1', 'K', 'AH0', 'T', ' ', '.']\n",
            "['P', 'AA1', 'P', 'Y', 'AH0', 'L', 'ER0', ' ', 'P', 'EH1', 'T', 'S', ' ', ',', ' ', 'F', 'AO1', 'R', ' ', 'IH0', 'G', 'Z', 'AE1', 'M', 'P', 'AH0', 'L', ' ', 'K', 'AE1', 'T', 'S', ' ', 'AH0', 'N', 'D', ' ', 'D', 'AA1', 'G', 'Z']\n",
            "['AY1', ' ', 'R', 'IH0', 'F', 'Y', 'UW1', 'Z', ' ', 'T', 'UW1', ' ', 'K', 'AH0', 'L', 'EH1', 'K', 'T', ' ', 'DH', 'AH0', ' ', 'R', 'EH1', 'F', 'Y', 'UW2', 'Z', ' ', 'ER0', 'AW1', 'N', 'D', ' ', 'HH', 'IY1', 'R', ' ', '.']\n",
            "['AY1', 'M', ' ', 'AE1', 'N', ' ', 'AE2', 'K', 'T', 'IH0', 'V', 'EY1', 'SH', 'AH0', 'N', 'IH0', 'S', 'T', ' ', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE OF THE HOMOGRAPH with same pronounciation\n",
        "homogrp_texts = [\"Miss Johnson teaches us psychology and Mary had to miss the gym to attend an event\"]\n",
        "\n",
        "for hg_t in homogrp_texts:\n",
        "  output = g2p(hg_t)\n",
        "  print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgld82iymL-9",
        "outputId": "6ed19de7-b608-4c29-d599-5f59b979d4e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M', 'IH1', 'S', ' ', 'JH', 'AA1', 'N', 'S', 'AH0', 'N', ' ', 'T', 'IY1', 'CH', 'AH0', 'Z', ' ', 'AH1', 'S', ' ', 'S', 'AY0', 'K', 'AA1', 'L', 'AH0', 'JH', 'IY0', ' ', 'AH0', 'N', 'D', ' ', 'M', 'EH1', 'R', 'IY0', ' ', 'HH', 'AE1', 'D', ' ', 'T', 'UW1', ' ', 'M', 'IH1', 'S', ' ', 'DH', 'AH0', ' ', 'JH', 'IH1', 'M', ' ', 'T', 'UW1', ' ', 'AH0', 'T', 'EH1', 'N', 'D', ' ', 'AE1', 'N', ' ', 'IH0', 'V', 'EH1', 'N', 'T']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE OF THE HOMOGRAPH with diff pronounciation\n",
        "homogrp_texts = [\"I will lead the team.\", \"The pipe is made of lead.\"]\n",
        "\n",
        "for hg_t in homogrp_texts:\n",
        "    output = g2p(hg_t)\n",
        "    print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bMysMNarfqP",
        "outputId": "832941a3-d685-4ec7-ed73-cf17bc72f283"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AY1', ' ', 'W', 'IH1', 'L', ' ', 'L', 'EH1', 'D', ' ', 'DH', 'AH0', ' ', 'T', 'IY1', 'M', ' ', '.']\n",
            "['DH', 'AH0', ' ', 'P', 'AY1', 'P', ' ', 'IH1', 'Z', ' ', 'M', 'EY1', 'D', ' ', 'AH1', 'V', ' ', 'L', 'EH1', 'D', ' ', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems the example with **lead (verb)** and **lead (noun)** still shows the same phoneme transcription in both cases. This can happen because some grapheme-to-phoneme (G2P) systems, like the one you're using (`g2p_en`), rely heavily on dictionary-based mappings or simpler models that may not always account for subtle contextual changes in pronunciation, especially in cases like homographs. Let’s review the behavior:\n",
        "\n",
        "### Homographs like \"lead\" (verb) and \"lead\" (noun)\n",
        "The expected behavior should have been:\n",
        "1. **Lead (verb)**: /liːd/ → `L IY1 D`\n",
        "2. **Lead (noun, metal)**: /lɛd/ → `L EH1 D`\n",
        "\n",
        "However, in practice, simpler G2P models might not always detect the exact contextual clues to correctly output different pronunciations for homographs. This could lead to both instances being transcribed similarly even when pronounced differently.\n",
        "\n",
        "### Improving Homograph Handling\n",
        "To handle homographs better, models would ideally incorporate deeper **contextual information** (e.g., syntactic parsing or semantics). Alternatively, **rule-based systems** or **neural models** trained on larger datasets with disambiguated pronunciations could help improve results.\n",
        "\n",
        "### Adjusting or Testing with More Complex Models\n",
        "If you're aiming for more accuracy, using models that incorporate syntactic or contextual disambiguation (e.g., BERT-based G2P models or models that integrate language modeling for phonetics) may yield more reliable transcriptions of homographs."
      ],
      "metadata": {
        "id": "7Ol49R2vtDHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EXAMPLE OF THE HOMOGRAPH with diff pronounciation\n",
        "homogrp_texts = [\"we live in Scotland but it was a live concert.\"]\n",
        "\n",
        "for hg_t in homogrp_texts:\n",
        "    output = g2p(hg_t)\n",
        "    print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIZqz3GTtHdD",
        "outputId": "f2d9d8aa-59a9-4e64-bb79-4fbd62d69902"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'IY1', ' ', 'L', 'AY1', 'V', ' ', 'IH0', 'N', ' ', 'S', 'K', 'AA1', 'T', 'L', 'AH0', 'N', 'D', ' ', 'B', 'AH1', 'T', ' ', 'IH1', 'T', ' ', 'W', 'AA1', 'Z', ' ', 'AH0', ' ', 'L', 'AY1', 'V', ' ', 'K', 'AA1', 'N', 'S', 'ER0', 'T', ' ', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In your example, the output shows that \"live\" is transcribed the same way for both meanings, which indicates that the G2P model didn't differentiate between the two pronunciations based on context.\n",
        "\n",
        "\"live\" (verb) in \"we live in Scotland\" is pronounced as /lɪv/.\n",
        "\"live\" (adjective) in \"it was a live concert\" is pronounced as /laɪv/.\n",
        "However, the model generated /lɪv/ for both instances, which is incorrect for the adjective meaning. This illustrates the challenge of homographs where pronunciation is context-dependent, highlighting the limitations of the G2P model in such cases."
      ],
      "metadata": {
        "id": "DB5fG0kYuh_I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwgf08cGuix0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}